{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe2b543",
   "metadata": {},
   "source": [
    "### Load Model and Target DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8579ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 1. 載入模型\n",
    "model = joblib.load(\"stacked_model_refined.pkl\")\n",
    "\n",
    "# 2. 載入新資料（不含 Quantity）\n",
    "df_new = pd.read_csv(\"online_0616d25.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b160b7f",
   "metadata": {},
   "source": [
    "### Missing Value Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873887f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['ShippingCost'] = df_new['ShippingCost'].fillna(df_new['ShippingCost'].median())\n",
    "df_new['WarehouseLocation'] = df_new['WarehouseLocation'].fillna(df_new['WarehouseLocation'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c304e888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description          0\n",
       "Quantity             0\n",
       "Year                 0\n",
       "Quarter              0\n",
       "Month                0\n",
       "DateofWeek           0\n",
       "Hour                 0\n",
       "InvoiceDate          0\n",
       "UnitPrice            0\n",
       "Country              0\n",
       "Discount             0\n",
       "PaymentMethod        0\n",
       "ShippingCost         0\n",
       "Category             0\n",
       "ShipmentProvider     0\n",
       "WarehouseLocation    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0acc94",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73010b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Features based on Importance:\n",
      "remainder__UnitPrice\n",
      "remainder__ShippingCost\n",
      "remainder__Discount\n",
      "encoder__WarehouseLocation_Paris\n",
      "encoder__ShipmentProvider_DHL\n",
      "encoder__ShipmentProvider_Royal Mail\n",
      "encoder__PaymentMethod_Credit Card\n",
      "encoder__PaymentMethod_paypall\n",
      "encoder__Category_Electronics\n",
      "encoder__DateofWeek_Fri\n",
      "encoder__ShipmentProvider_UPS\n",
      "encoder__Category_Stationery\n",
      "encoder__Category_Accessories\n",
      "encoder__Category_Apparel\n",
      "encoder__DateofWeek_Sun\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define your categorical columns\n",
    "categorical_columns = df_new.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# numerical_cols = df_new.select_dtypes(include=['int64', 'float64'])\n",
    "# Specify your categorical columns\n",
    "\n",
    "# Define the encoder and the transformation\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Separate features and target\n",
    "X = df_new.drop('Quantity', axis=1)\n",
    "y = df_new['Quantity']\n",
    "\n",
    "# Encode the features\n",
    "X_encoded = column_transformer.fit_transform(X)\n",
    "feature_names_encoded = column_transformer.get_feature_names_out()\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Combine feature names and their importances, sort them, and select the top 15\n",
    "features_importances = sorted(zip(feature_names_encoded, importances), key=lambda x: x[1], reverse=True)[:15]\n",
    "\n",
    "# Extract just the feature names for the top 15\n",
    "top_features = [feature for feature, importance in features_importances]\n",
    "\n",
    "# Print the top 15 features\n",
    "print(\"Top 15 Features based on Importance:\")\n",
    "for feature in top_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8484981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Features:\n",
      "UnitPrice\n",
      "ShippingCost\n",
      "Discount\n",
      "WarehouseLocation_Paris\n",
      "ShipmentProvider_DHL\n",
      "ShipmentProvider_Royal Mail\n",
      "PaymentMethod_Credit Card\n",
      "PaymentMethod_paypall\n",
      "Category_Electronics\n",
      "DateofWeek_Fri\n",
      "ShipmentProvider_UPS\n",
      "Category_Stationery\n",
      "Category_Accessories\n",
      "Category_Apparel\n",
      "DateofWeek_Sun\n"
     ]
    }
   ],
   "source": [
    "# Trim the first word and underscores\n",
    "feature_selected = ['__'.join(feature.split('__')[1:]) for feature in top_features]\n",
    "\n",
    "# Print the trimmed feature names\n",
    "print(\"Trimmed Features:\")\n",
    "for feature in feature_selected:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9ff32",
   "metadata": {},
   "source": [
    "### Onehot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b3dc0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5934 entries, 0 to 5933\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Description        5934 non-null   object \n",
      " 1   Quantity           5934 non-null   int64  \n",
      " 2   Year               5934 non-null   object \n",
      " 3   Quarter            5934 non-null   object \n",
      " 4   Month              5934 non-null   object \n",
      " 5   DateofWeek         5934 non-null   object \n",
      " 6   Hour               5934 non-null   object \n",
      " 7   InvoiceDate        5934 non-null   object \n",
      " 8   UnitPrice          5934 non-null   float64\n",
      " 9   Country            5934 non-null   object \n",
      " 10  Discount           5934 non-null   float64\n",
      " 11  PaymentMethod      5934 non-null   object \n",
      " 12  ShippingCost       5934 non-null   float64\n",
      " 13  Category           5934 non-null   object \n",
      " 14  ShipmentProvider   5934 non-null   object \n",
      " 15  WarehouseLocation  5934 non-null   object \n",
      "dtypes: float64(3), int64(1), object(12)\n",
      "memory usage: 741.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_new['Year'] = df_new['Year'].astype('object')\n",
    "df_new['Hour'] = df_new['Hour'].astype('object')\n",
    "\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6755bb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Quantity  UnitPrice  Discount  ShippingCost  Description_Backpack  \\\n",
      "0        18      28.65      0.41         28.06                   0.0   \n",
      "1        33      85.88      0.05         11.00                   0.0   \n",
      "2        47      75.47      0.28         14.92                   0.0   \n",
      "3        18      67.85      0.36         16.41                   0.0   \n",
      "4        45      98.30      0.06         25.36                   0.0   \n",
      "\n",
      "   Description_Blue Pen  Description_Desk Lamp  Description_Headphones  \\\n",
      "0                   0.0                    0.0                     0.0   \n",
      "1                   0.0                    0.0                     0.0   \n",
      "2                   0.0                    0.0                     0.0   \n",
      "3                   0.0                    0.0                     0.0   \n",
      "4                   1.0                    0.0                     0.0   \n",
      "\n",
      "   Description_Notebook  Description_Office Chair  ...  Category_Stationery  \\\n",
      "0                   0.0                       0.0  ...                  0.0   \n",
      "1                   0.0                       1.0  ...                  0.0   \n",
      "2                   0.0                       0.0  ...                  0.0   \n",
      "3                   0.0                       1.0  ...                  1.0   \n",
      "4                   0.0                       0.0  ...                  0.0   \n",
      "\n",
      "   ShipmentProvider_DHL  ShipmentProvider_FedEx  ShipmentProvider_Royal Mail  \\\n",
      "0                   0.0                     0.0                          0.0   \n",
      "1                   0.0                     1.0                          0.0   \n",
      "2                   0.0                     0.0                          0.0   \n",
      "3                   0.0                     0.0                          1.0   \n",
      "4                   0.0                     0.0                          0.0   \n",
      "\n",
      "   ShipmentProvider_UPS  WarehouseLocation_Amsterdam  \\\n",
      "0                   1.0                          0.0   \n",
      "1                   0.0                          0.0   \n",
      "2                   1.0                          0.0   \n",
      "3                   0.0                          1.0   \n",
      "4                   1.0                          0.0   \n",
      "\n",
      "   WarehouseLocation_Berlin  WarehouseLocation_London  \\\n",
      "0                       0.0                       1.0   \n",
      "1                       0.0                       0.0   \n",
      "2                       1.0                       0.0   \n",
      "3                       0.0                       0.0   \n",
      "4                       0.0                       0.0   \n",
      "\n",
      "   WarehouseLocation_Paris  WarehouseLocation_Rome  \n",
      "0                      0.0                     0.0  \n",
      "1                      1.0                     0.0  \n",
      "2                      0.0                     0.0  \n",
      "3                      0.0                     0.0  \n",
      "4                      1.0                     0.0  \n",
      "\n",
      "[5 rows x 6022 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identifying categorical columns in 'df_new'\n",
    "categorical_cols = df_new.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "\n",
    "# Initializing the OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False, drop=None)  # `drop='first'` to avoid dummy variable trap\n",
    "\n",
    "# Fitting and transforming the categorical columns\n",
    "# Note: `.fit_transform()` expects a 2D array, hence the double brackets `[[column]]`\n",
    "encoded_data = ohe.fit_transform(df_new[categorical_cols])\n",
    "\n",
    "# Creating a DataFrame with the encoded data\n",
    "# `get_feature_names_out()` gives new column names\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=ohe.get_feature_names_out(categorical_cols))\n",
    "\n",
    "\n",
    "\n",
    "# Concatenating the encoded_df with the original DataFrame (minus the categorical columns)\n",
    "df_new_numeric = df_new.drop(columns=categorical_cols)\n",
    "df_encoded = pd.concat([df_new_numeric.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e411c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2401050\\AppData\\Local\\Temp\\ipykernel_19496\\2709672253.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['Quantity'] = df_encoded['Quantity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>ShippingCost</th>\n",
       "      <th>Discount</th>\n",
       "      <th>WarehouseLocation_Paris</th>\n",
       "      <th>ShipmentProvider_DHL</th>\n",
       "      <th>ShipmentProvider_Royal Mail</th>\n",
       "      <th>PaymentMethod_Credit Card</th>\n",
       "      <th>PaymentMethod_paypall</th>\n",
       "      <th>Category_Electronics</th>\n",
       "      <th>DateofWeek_Fri</th>\n",
       "      <th>ShipmentProvider_UPS</th>\n",
       "      <th>Category_Stationery</th>\n",
       "      <th>Category_Accessories</th>\n",
       "      <th>Category_Apparel</th>\n",
       "      <th>DateofWeek_Sun</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.65</td>\n",
       "      <td>28.06</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.88</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.47</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.85</td>\n",
       "      <td>16.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.30</td>\n",
       "      <td>25.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnitPrice  ShippingCost  Discount  WarehouseLocation_Paris  \\\n",
       "0      28.65         28.06      0.41                      0.0   \n",
       "1      85.88         11.00      0.05                      1.0   \n",
       "2      75.47         14.92      0.28                      0.0   \n",
       "3      67.85         16.41      0.36                      0.0   \n",
       "4      98.30         25.36      0.06                      1.0   \n",
       "\n",
       "   ShipmentProvider_DHL  ShipmentProvider_Royal Mail  \\\n",
       "0                   0.0                          0.0   \n",
       "1                   0.0                          0.0   \n",
       "2                   0.0                          0.0   \n",
       "3                   0.0                          1.0   \n",
       "4                   0.0                          0.0   \n",
       "\n",
       "   PaymentMethod_Credit Card  PaymentMethod_paypall  Category_Electronics  \\\n",
       "0                        0.0                    0.0                   0.0   \n",
       "1                        0.0                    0.0                   0.0   \n",
       "2                        1.0                    0.0                   0.0   \n",
       "3                        1.0                    0.0                   0.0   \n",
       "4                        1.0                    0.0                   0.0   \n",
       "\n",
       "   DateofWeek_Fri  ShipmentProvider_UPS  Category_Stationery  \\\n",
       "0             0.0                   1.0                  0.0   \n",
       "1             0.0                   0.0                  0.0   \n",
       "2             0.0                   1.0                  0.0   \n",
       "3             0.0                   0.0                  1.0   \n",
       "4             0.0                   1.0                  0.0   \n",
       "\n",
       "   Category_Accessories  Category_Apparel  DateofWeek_Sun  Quantity  \n",
       "0                   1.0               0.0             0.0        18  \n",
       "1                   1.0               0.0             0.0        33  \n",
       "2                   0.0               1.0             0.0        47  \n",
       "3                   0.0               0.0             0.0        18  \n",
       "4                   0.0               0.0             0.0        45  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include 'quantity' in the data frame\n",
    "df_selected = df_encoded[feature_selected]\n",
    "df_selected['Quantity'] = df_encoded['Quantity']\n",
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bc61cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data frame by exporting it\n",
    "df_selected.to_csv('df_selected0619.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f23d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f3df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0188a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "533102d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2401050\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 16 features, but RandomForestRegressor is expecting 6021 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m X_new \u001b[38;5;241m=\u001b[39m df_selected\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 4. 預測\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_selected[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Quantity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 5. 輸出結果\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_selected\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\2401050\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1065\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1063\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1065\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\2401050\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:637\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\2401050\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2975\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2975\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\2401050\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2842\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 16 features, but RandomForestRegressor is expecting 6021 features as input."
     ]
    }
   ],
   "source": [
    "# 3. 保留與訓練時一致的特徵欄位（你自己補上 feature_columns）\n",
    "X_new = df_selected\n",
    "\n",
    "# 4. 預測\n",
    "df_selected['Predicted_Quantity'] = model.predict(X_new)\n",
    "\n",
    "# 5. 輸出結果\n",
    "df_selected.to_csv(\"predicted_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
